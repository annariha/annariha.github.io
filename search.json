[
  {
    "objectID": "projects/workflows-multiverse/index.html",
    "href": "projects/workflows-multiverse/index.html",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "",
    "text": "How can we combine transparent creation of sets of models (multiverse analysis) with recipes for model building and evaluation (Bayesian workflow) to support decision making in Bayesian model building scenarios?"
  },
  {
    "objectID": "projects/workflows-multiverse/index.html#existing-work",
    "href": "projects/workflows-multiverse/index.html#existing-work",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "Existing work",
    "text": "Existing work\n\nBayesian workflow as introduced in Gelman et al. (2020), also discussed in e.g., Martin, Kumar, and Lao (2021) and a blogpost by Michael Betancourt1\nBayesian model evaluation, and comparison (e.g., Vehtari and Ojanen (2012), Piironen and Vehtari (2017))\nprior and likelihood sensitivity checks in \\(\\texttt{R}\\)-package priorsense2 (Kallioinen et al. 2021)\n(posterior) calibration checks with Säilynoja, Bürkner, and Vehtari (2022)\nmodel comparison with \\(\\texttt{R}\\)-package loo (Vehtari et al. 2022)\nmultiverse analysis (Steegen et al. 2016) and multiverse \\(\\texttt{R}\\)-package (Sarma et al. 2021)\nexplorable multiverse analyses (Dragicevic et al. 2019)\ncreating multiverse analysis scripts, exploring results with Boba (Liu et al. 2021)\nsurvey of visualisation of multiverse analyses (Hall et al. 2022)\nmodular STAN (Bernstein, Vákár, and Wing 2020)\nmodelling multiverse analysis (for machine learning) (Bell et al. 2022)\n\nThe following figures show two variants of flowcharts for Bayesian workflows with different levels of detail as well as crucial and optional steps3. Similarities are, for example, (1) iterating when needed, and (2) connecting model and computation.\n\n\n\nFigure 1: Bayesian Workflow in (Gelman et al. 2020)\n\n\n\n\n\nFigure 2: Bayesian Workflow in (Martin, Kumar, and Lao 2021)."
  },
  {
    "objectID": "projects/workflows-multiverse/index.html#challenges-in-bayesian-workflows",
    "href": "projects/workflows-multiverse/index.html#challenges-in-bayesian-workflows",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "Challenges in Bayesian workflows",
    "text": "Challenges in Bayesian workflows\n\nmulti-attribute multi-objective scenarios\nnavigating necessary vs. “nice-to-have” steps\nstopping criteria and sufficient exploration\niterative model building, while transparent and robust\ncommunicating results of multiple models\n\n\n\nWhat is a “good enough” model?4\n\ndepends (to some extent) on objectives of the analysis\ndomain knowledge\npassing prior predictive checks\n“good” priors\nconvergence of sampling algorithms\nposterior calibration\npassing posterior predictive checks\npredictive performance\nexplainability\n…"
  },
  {
    "objectID": "projects/workflows-multiverse/index.html#transparent-exploration",
    "href": "projects/workflows-multiverse/index.html#transparent-exploration",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "Transparent Exploration",
    "text": "Transparent Exploration\n\n\n\nFigure 3: Multiverse analysis compared to other approaches, from (Dragicevic et al. 2019).\n\n\n\n\n\n\n\n\nFigure 4: What is a multiverse analysis report? in (Hall et al. 2022).\n\n\n\n\n\n\n\nFigure 5: Multiverse analysis in Bayesian workflow in (Gelman et al. 2020).\n\n\n\n\n\nMultiverse analysis provides a way to transparently define and fit several models at once (Steegen et al. (2016)). This allows to define and investigate several models at once.\nIn a workflow that requires iterations, this could allow parallel exploration, thereby, increasing efficiency. On the other hand, this exploration of sets of models necessarily depends on researcher/data analyst/user choices, and is subject to computational and cognitive constraints.\nReasoning on a set of models can be challenging, and dependence structures and different weights of modelling choices are not immediately clear when confronted with a large collection of possible models (see e.g., Hall et al. (2022))."
  },
  {
    "objectID": "projects/workflows-multiverse/index.html#differences-and-structure-in-a-set-of-models",
    "href": "projects/workflows-multiverse/index.html#differences-and-structure-in-a-set-of-models",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "Differences and structure in a set of models",
    "text": "Differences and structure in a set of models\nGiven a set of \\(m\\) models \\(\\mathcal{M} = \\{M_1, M_2, ..., M_m\\}\\), let \\(C_1, \\cdots, C_k\\) denote \\(k\\) different modelling choices. If, for example, \\(C_1 = \\{\\text{\"poisson\"}, \\text{\"negbinomial\"}\\}\\), \\(C_2 = \\{\\text{\"Trt\"}\\}\\) and \\(C_3 = \\{ \\text{\"no zAge\"}, \\text{\"zAge\"} \\}\\), one could draw networks of the resulting four models solely based on how much they differ in each of the conditions.\nBelow, the left-hand side shows one step differences, while the right-hand side includes two step differences for models created using the above modelling choices \\(C_1, C_2\\) and \\(C_3\\).\n\n\n\n\n\n\n\n\n\nD\n\n  \n\nA\n\n Poisson(Trt)   \n\nB\n\n Poisson(Trt+zAge)   \n\nA–B\n\n   \n\nC\n\n Negbinom(Trt)   \n\nA–C\n\n   \n\nD\n\n Negbinom(Trt+zAge)   \n\nB–D\n\n   \n\nC–D\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nD\n\n  \n\nA\n\n Poisson(Trt)   \n\nB\n\n Poisson(Trt+zAge)   \n\nA–B\n\n   \n\nC\n\n Negbinom(Trt)   \n\nA–C\n\n   \n\nD\n\n Negbinom(Trt+zAge)   \n\nB–D\n\n   \n\nC–B\n\n     \n\nC–D\n\n   \n\nD–A"
  },
  {
    "objectID": "projects/workflows-multiverse/index.html#filtering-and-flagging",
    "href": "projects/workflows-multiverse/index.html#filtering-and-flagging",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "Filtering and Flagging",
    "text": "Filtering and Flagging\nWhat models need further investigation (or can be safely excluded) due to, for example\n\nprior-data conflict\nconvergence issues\ncalibration problems for posterior\nproblematic posterior predictive checks\nlow predictive performance\n\nFiltering (or flagging) also serves as a tool to indicate that we are in fact at a certain decision point in the Bayesian workflow (e.g., if computation failed, go to “Addressing computational issues (5)”, see Figure 1)."
  },
  {
    "objectID": "projects/workflows-multiverse/index.html#case-study-brmsepilepsy",
    "href": "projects/workflows-multiverse/index.html#case-study-brmsepilepsy",
    "title": "Bayesian Workflow and Multiverse Analysis",
    "section": "Case Study: brms::epilepsy",
    "text": "Case Study: brms::epilepsy\nFor this case study, we use the dataset brms::epilepsy from the \\(\\texttt{R}\\)-package brms (Bürkner (2017)) with 236 observations containing information on the following 9 variables, originally from Thall and Vail (1990) and Breslow and Clayton (1993):5\n\n\\(\\texttt{Age}\\): age of patients in years\n\\(\\texttt{Base}\\): seizure count at 8-weeks baseline\n\\(\\texttt{Trt}\\): 0 or 1 indicating if patient received anti-convulsant therapy\n\\(\\texttt{patient}\\): patient number\n\\(\\texttt{visit}\\): session number from 1 (first visit) to 4 (last visit)\n\\(\\texttt{count}\\): seizure count between two visits\n\\(\\texttt{obs}\\): observation number (unique identifier for each observation)\n\\(\\texttt{zAge}\\): Standardized Age\n\\(\\texttt{zBase}\\): Standardized Base\n\nFirst, we create a dataframe of combinations of modelling choices. Here, we consider two different observation families (poisson and negbinomial), two different prior settings (brms default setting and horseshoe prior with df=3 for the population-level effects), different combinations of covariates, models with and without random effects on the level of each patient and/or visit, as well as models with and without interaction effect zBase * Trt. This leads to \\(96\\) models.\n\n# load data ####\ndat <- brms::epilepsy \noutcome_str <- \"count\"\n\n# create dataframe of combinations of model components ####\n\n# observation families\nfamilies <- list(poisson = poisson(), \n                 negbinomial = negbinomial())\n\n# priors \npriors <- list(brms_default = NULL, \n               brms_horseshoe = set_prior(\"horseshoe(3)\")\n)\n\ncombinations_df <- expand.grid(\n  family = names(families),\n  prior = priors,\n  # fixed effects \n  Trt = c(\"\", \"Trt\"), \n  zBase = c(\"\", \"zBase\"),\n  zAge = c(\"\", \"zAge\"),\n  # random effects, no observation level r.e.\n  patient = c(\"\", \"(1 | patient)\"),\n  visit = c(\"\", \"(1 | visit)\")\n)\n\ncombinations_df <- combinations_df |> \n  # add interaction effect in the rows where treatment was left out, (i.e., where Trt == \"\")\n  mutate(zBaseTrt = factor(\n    case_when(\n      Trt == \"Trt\" ~ \"\",\n      Trt == \"\" ~ \"zBase * Trt\"))) |> \n  # filter out rows with interaction and zBase\n  filter(!(zBaseTrt == \"zBase * Trt\" & combinations_df$zBase == \"zBase\"))\n\nThen, we can fit models in parallel and evaluate the list of models jointly. This allows us to obtain joint summaries of model evaluation metrics for all models. An example of such a summary table is given below with results for the six models with highest PBMA weights and no divergent transitions in the collection of all \\(96\\) models.\n\n\n\n\n \n  \n      \n    rhats_raw \n    div_trans \n    elpd_diff \n    se_diff \n    elpd_loo \n    se_elpd_loo \n    p_loo \n    se_p_loo \n    looic \n    se_looic \n    pbma_weight \n  \n \n\n  \n    negbinomial(count ~ Trt+zBase+(1 | patient)), brms_default \n    1.0019177 \n    0 \n    -0.6077353 \n    0.6633197 \n    -614.7457 \n    16.99723 \n    40.61555 \n    4.271803 \n    1229.491 \n    33.99447 \n    0.1030463 \n  \n  \n    negbinomial(count ~ Trt+zBase+zAge+(1 | patient)), brms_default \n    1.0009256 \n    0 \n    -0.9609591 \n    0.7357013 \n    -615.0990 \n    16.93908 \n    40.88040 \n    4.235912 \n    1230.198 \n    33.87816 \n    0.0732736 \n  \n  \n    negbinomial(count ~ zBase * Trt+(1 | patient)), brms_default \n    0.9999913 \n    0 \n    -1.0315128 \n    0.6751808 \n    -615.1695 \n    17.04660 \n    39.84465 \n    4.046008 \n    1230.339 \n    34.09320 \n    0.0674200 \n  \n  \n    negbinomial(count ~ zBase * Trt+zAge+(1 | patient)), brms_default \n    1.0012496 \n    0 \n    -1.4176538 \n    0.8658291 \n    -615.5557 \n    17.02404 \n    41.58619 \n    4.331625 \n    1231.111 \n    34.04808 \n    0.0465748 \n  \n  \n    negbinomial(count ~ Trt+(1 | patient)), brms_default \n    1.0041909 \n    0 \n    -4.5562196 \n    3.1165026 \n    -618.6942 \n    17.24316 \n    46.92558 \n    4.449165 \n    1237.388 \n    34.48633 \n    0.0158738 \n  \n  \n    negbinomial(count ~ Trt+zAge+(1 | patient)), brms_default \n    1.0010792 \n    0 \n    -4.6430282 \n    3.0686439 \n    -618.7810 \n    17.17285 \n    46.73492 \n    4.444467 \n    1237.562 \n    34.34569 \n    0.0139103"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Anna Elisabeth Riha",
    "section": "",
    "text": "Bayesian Workflow and Multiverse Analysis\n\n\n\n\n\n\n\nideas\n\n\ncase study\n\n\n\n\n\n\n\n\n\n\n\nJan 4, 2024\n\n\nAnna Elisabeth Riha\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently working as a doctoral researcher in the Probabilistic Machine Learning (PML) group at Aalto University in Finland, supervised by Aki Vehtari and Antti Oulasvirta."
  }
]