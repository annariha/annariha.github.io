[
  {
    "objectID": "casestudies/workflows-multiverse/index.html",
    "href": "casestudies/workflows-multiverse/index.html",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(readr)\nlibrary(tictoc)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(tinytable)\nlibrary(reactable)\nlibrary(htmltools)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(future)\nlibrary(furrr)\nlibrary(cmdstanr)\n\n# load helper functions\nhelpers &lt;- list.files(path = here::here(\"projects\", \"workflows-multiverse\"), pattern = \"*.R$\", full.names = TRUE)\nsapply(helpers, source)\n\n\nnamed list()\nHow can we combine transparent creation of sets of models (multiverse analysis) with recipes for model building and evaluation (Bayesian workflow) to support Bayesian model building?\nBayesian model building consists of several intertwined tasks and can involve the iterative consideration of various candidate models (see, e.g., Gelman et al. (2020), Martin, Kumar, and Lao (2021)). Aspects like model evaluation, model criticism and model comparison can motivate the consideration of multiple models and are essential when searching for models that are sufficient for accurate prediction and robust decision-making (see, e.g., Vehtari and Ojanen (2012), Piironen and Vehtari (2017)).\nWe propose iterative filtering for multiverse analysis to balance the advantages of a joint investigation of multiple candidate models with the potentially overwhelming tasks of evaluating and comparing multiple models at once.\nRecommendations from Bayesian workflows and utilities of Bayesian models provide filtering criteria. In particular, we are (for now) focusing on filtering out largely inferior models and identifying minimum viable candidate models for further analyses. A minimum viable Bayesian model is a model that\nWhy do we care about these aspects?\nFirst, we cannot trust conclusions implied by a model if we are not able to obtain reliable posterior samples in the first place. Since we rely on approximations, we need to check whether computation was successful, for example, via convergence checks. Secondly, if a model lacks predictive abilities, it is not useful for decision making."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#analysing-an-anticonvulsant-for-patients-with-epilepsy",
    "href": "casestudies/workflows-multiverse/index.html#analysing-an-anticonvulsant-for-patients-with-epilepsy",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Analysing an anticonvulsant for patients with epilepsy",
    "text": "Analysing an anticonvulsant for patients with epilepsy\nLet’s see how iterative filtering can be applied to multiverse analyses of anticonvulsant therapy for patients with epilepsy.\nWe use the dataset brms::epilepsy from the \\(\\texttt{R}\\)-package brms (Bürkner (2017)) with 236 observations of 59 patients, originally from Thall and Vail (1990) and Breslow and Clayton (1993). The data contains information on:\n\n\\(\\texttt{Trt}\\): 0 or 1 if patient received anticonvulsant therapy\n\\(\\texttt{Age}\\): age of patients in years\n\\(\\texttt{Base}\\): seizure count at 8-week baseline\n\\(\\texttt{zAge}\\): standardised age\n\\(\\texttt{zBase}\\): standardised baseline\n\\(\\texttt{patient}\\): patient number\n\\(\\texttt{visit}\\): session number from 1 (first visit) to 4 (last visit)\n\\(\\texttt{obs}\\): unique identifier for each observation\n\\(\\texttt{count}\\): seizure count between two visits.\n\nHere is a quick glimpse:\n\n\nCode\ntt(head(brms::epilepsy, 3))\n\n\n \n\n  \n    \n    \n    tinytable_w9d5igvqaj0feobf5mmu\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Age\n                Base\n                Trt\n                patient\n                visit\n                count\n                obs\n                zAge\n                zBase\n              \n        \n        \n        \n                \n                  31\n                  11\n                  0\n                  1\n                  1\n                  5\n                  1\n                   0.4249950\n                  -0.7571728\n                \n                \n                  30\n                  11\n                  0\n                  2\n                  1\n                  3\n                  2\n                   0.2652835\n                  -0.7571728\n                \n                \n                  25\n                   6\n                  0\n                  3\n                  1\n                  2\n                  3\n                  -0.5332740\n                  -0.9444033"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#an-initial-multiverse-of-models",
    "href": "casestudies/workflows-multiverse/index.html#an-initial-multiverse-of-models",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "An initial multiverse of models",
    "text": "An initial multiverse of models\nTo analyse the effect of anticonvulsant therapy, we are interested in the number of seizures, that is, non-negative counts. We choose models with Poisson and negative Binomial distributional families for the observations because they are suitable for non-negative integers. We want to investigate models with default priors in brms as well as models with a horseshoe prior with three degrees of freedom for the population-level effects. Additionally, we evaluate different combinations of covariates as well as models with and without interaction effect zBase*Trt. The combination of these modelling choices leads to \\(2 \\times 2 \\times 6 = 24\\) candidate models.\n\n\nCode\n# create dataframe of combinations of model components ####\ncombinations_df &lt;- expand.grid(\n  family = names(list(poisson = poisson(), negbinomial = negbinomial())),\n  prior = list(brms_default = \"NULL\", brms_horseshoe = \"horseshoe(3)\"),\n  # population-level effects\n  Trt = c(\"\", \"Trt\"), \n  zBase = c(\"\", \"zBase\"),\n  zAge = c(\"\", \"zAge\")\n)\n\ncombinations_df &lt;- combinations_df |&gt; \n  # add interaction effect in the rows where treatment was left out, (i.e., where Trt == \"\")\n  mutate(zBaseTrt = factor(\n    case_when(\n      Trt == \"Trt\" ~ \"\",\n      Trt == \"\" ~ \"zBase * Trt\"))) |&gt; \n  # filter out rows with interaction and zBase\n  filter(!(zBaseTrt == \"zBase * Trt\" & combinations_df$zBase == \"zBase\"))\n\noutcome_str &lt;- \"count\" \n\ncombinations_df &lt;- combinations_df |&gt;  \n  # add outcome name \n  mutate(outcome = rep_len(outcome_str, NROW(combinations_df))) |&gt;\n  # add prior names for easier summarising, plotting etc. \n  mutate(priors = names(combinations_df$prior)) |&gt;\n  # reorder to have outcome name, family and treatment effects first \n  select(outcome, family, priors, prior, Trt, zBaseTrt, everything())\n\n\n\n\nCode\nmodels_combs_df &lt;- combinations_df |&gt;\n  mutate(modelnames = apply(combinations_df, 1, build_name)) |&gt;\n  mutate(formula = apply(combinations_df, 1, build_formula_string))\n\n# workhorse: fit models ####\ntic()\nfuture::plan(multisession)\nmodels_combs_df$modelfits &lt;- combinations_df |&gt;\n  group_nest(row_number()) |&gt;\n  pull(data) |&gt;\n  furrr::future_map(~build_fit(.x, dataset = brms::epilepsy), .options=furrr_options(seed=TRUE))\nfuture::plan(sequential)\ntoc()\n\n# add draws df ####\nmodels_combs_df &lt;- models_combs_df |&gt;\n  mutate(model_id = paste0(\"Model \", row_number())) |&gt;\n  mutate(draws_df = purrr::map(purrr::map(modelfits, pluck), posterior::as_draws_df))"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#evaluating-the-multiverse",
    "href": "casestudies/workflows-multiverse/index.html#evaluating-the-multiverse",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Evaluating the multiverse",
    "text": "Evaluating the multiverse\n\n\nCode\n# load results for initial multiverse of 24 models \ninitial_multiverse &lt;- readr::read_rds(here::here(\"data\", \"initial_multiverse.rds\"))"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#filtering",
    "href": "casestudies/workflows-multiverse/index.html#filtering",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Filtering",
    "text": "Filtering"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#extending-the-filtered-set-of-models",
    "href": "casestudies/workflows-multiverse/index.html#extending-the-filtered-set-of-models",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Extending the filtered set of models",
    "text": "Extending the filtered set of models\n\n\nCode\n# load results for 192 models\n#extended_multiverse &lt;- readr::read_rds(here::here(\"data\", \"models_combs_df.rds\"))"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#stabilising-likelihoods-with-integration",
    "href": "casestudies/workflows-multiverse/index.html#stabilising-likelihoods-with-integration",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Stabilising likelihoods with integration",
    "text": "Stabilising likelihoods with integration\nThe function takes as input a row of a dataframe containing modelling choices and the name of the outcome where each row corresponds to one set of modelling choices, that is, one model in the multiverse. This function uses the helper function build_fit() which is using brms::brm() to fit one model based on a row vector of modelling choices.\n\n\nCode\nbuild_loglik &lt;- function(row, ...){\n  \n  # get model fit ####\n  modelfit = build_fit(row, ...)\n  # get posterior draws\n  draws_df = posterior::as_draws_df(modelfit)\n  \n  # reformat draws to get z's and sd ####\n  input_df &lt;- draws_df |&gt; \n    tidyr::nest(rs = starts_with(\"r_obs\"),\n                sd = matches(\"sd_obs__Intercept\")) |&gt;\n    mutate(rs = map(rs, unlist),\n           sd = map_dbl(sd, ~matrix(unlist(.x), ncol = 1))) |&gt;\n    rowwise() |&gt;\n    mutate(zs = list(unlist(rs) / sd))\n  \n  # extract linpred ####\n  # from brms docs: \"[posterior] draws before applying any link functions or other transformations\"\n  lin_pred = brms::posterior_linpred(modelfit)\n  # standardized group-level effects\n  zs_df = data.frame(matrix(unlist(input_df$zs), ncol=NROW(modelfit$data), byrow=T))\n  # actual group-level effects\n  rs_df = data.frame(matrix(unlist(input_df$rs), ncol=NROW(modelfit$data), byrow=T)) \n  lin_pred_without = lin_pred - rs_df # different values across iterations, same value for each obs\n  \n  # outcome ####\n  outcome_name = row[[\"outcome\"]]\n  outcome = as.numeric(unlist(modelfit$data[outcome_name]))\n  \n  # results for all observations and iterations with integrate() ####\n  log_lik = matrix(data=NA, nrow=brms::nchains(modelfit)*brms::niterations(modelfit), ncol=NROW(modelfit$data))\n  # iterate to get loglik\n  for (i in seq(NROW(input_df))){\n    for (j in seq(NROW(modelfit$data))){\n      zs &lt;- zs_df[i,j]\n      sd_obs &lt;- input_df$sd[i]\n      linpreds_minus_re &lt;- lin_pred_without[i,j]\n      y &lt;- as.numeric(outcome[j])\n      integrand &lt;- function(zs, \n                            sd_obs,\n                            y, \n                            linpreds_minus_re){\n        # function defines integrand for integrate()\n        # in Stan code: std_normal_lpdf(z_1)\n        z_term &lt;- dnorm(zs,\n                        mean = 0, \n                        sd = 1,\n                        log = TRUE)\n        # in Stan code: poisson_log_lpmf(Yi[1] | r_1_1 + linpred_minus_re)\n        fit_term &lt;- dpois(x = y, \n                          lambda = exp((zs*sd_obs)  + linpreds_minus_re),\n                          log = TRUE)\n        result = exp(z_term + fit_term)\n        return(result)\n      }\n      #print(paste0(\"Iteration: \", i, \" Observation: \", j, \" sd_obs: \", sd_obs, \" linpreds: \", linpreds_minus_re, \" y: \", y))\n      log_lik[i,j] &lt;- log(integrate(integrand, \n                                    lower = -Inf,\n                                    upper = Inf,\n                                    sd_obs = sd_obs,\n                                    y = y,\n                                    linpreds_minus_re = linpreds_minus_re)$value)\n    }\n  }\n  # add names to matrix \n  colnames(log_lik) &lt;- paste0(\"log_lik[\", seq(NROW(modelfit$data)), \"]\")\n  # convert matrix of log_lik values to array\n  log_lik_array &lt;- array(log_lik, c(brms::niterations(modelfit), brms::nchains(modelfit), NROW(modelfit$data)))\n  # set dimnames of array\n  dimnames(log_lik_array) &lt;- list(iteration = seq(brms::niterations(modelfit)),\n                                  chain = seq(brms::nchains(modelfit)),\n                                  variable =  paste0(\"log_lik[\", seq(NROW(modelfit$data)), \"]\"))\n  # convert into draws array\n  log_lik_array &lt;- posterior::as_draws(log_lik_array)\n  # output: a log-likelihood array \n  return(log_lik_array)\n}"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#existing-work",
    "href": "casestudies/workflows-multiverse/index.html#existing-work",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Existing work",
    "text": "Existing work\n\n\nprior and likelihood sensitivity checks in \\(\\texttt{R}\\)-package priorsense1 (Kallioinen et al. 2021)\n(posterior) calibration checks with Säilynoja, Bürkner, and Vehtari (2022)\nmodel comparison with \\(\\texttt{R}\\)-package loo (Vehtari et al. 2022)\nmultiverse analysis (Steegen et al. 2016) and multiverse \\(\\texttt{R}\\)-package (Sarma et al. 2021)\nexplorable multiverse analyses (Dragicevic et al. 2019)\ncreating multiverse analysis scripts, exploring results with Boba (Liu et al. 2021)\nsurvey of visualisation of multiverse analyses (Hall et al. 2022)\nmodular STAN (Bernstein, Vákár, and Wing 2020)\nmodelling multiverse analysis (for machine learning) (Bell et al. 2022)\n\n1 https://github.com/n-kall/priorsense2 Another interesting variant of a flowchart for Bayesian workflow can be found in Michael Betancourt’s blogpost “Principled Bayesian Workflow”.The following figures show two variants of flowcharts for Bayesian workflows with different levels of detail as well as crucial and optional steps2. Similarities are, for example, (1) iterating when needed, and (2) connecting model and computation.\n\n\n\n\n\n\nFigure 1: Bayesian Workflow in (Gelman et al. 2020)\n\n\n\n\n\n\n\n\n\nFigure 2: Bayesian Workflow in (Martin, Kumar, and Lao 2021)."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#challenges-in-bayesian-workflows",
    "href": "casestudies/workflows-multiverse/index.html#challenges-in-bayesian-workflows",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Challenges in Bayesian workflows",
    "text": "Challenges in Bayesian workflows\n\nmulti-attribute multi-objective scenarios\nnavigating necessary vs. “nice-to-have” steps\nstopping criteria and sufficient exploration\niterative model building, while transparent and robust\ncommunicating results of multiple models\n\n\n\nWhat is a “good enough” model?3\n\ndepends (to some extent) on objectives of the analysis\ndomain knowledge\npassing prior predictive checks\n“good” priors\nconvergence of sampling algorithms\nposterior calibration\npassing posterior predictive checks\npredictive performance\nexplainability\n…\n\n3 This is connected to the concept of a reference model (e.g., Vehtari and Ojanen (2012) and for projection predictive inference (Piironen et al. 2022)) as well as ideas on Bayesian model taxonomy as outlined, for example, by Bürkner, Scholz, and Radev (2022)."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#transparent-exploration",
    "href": "casestudies/workflows-multiverse/index.html#transparent-exploration",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Transparent Exploration",
    "text": "Transparent Exploration\n\n\n\n\n\n\nFigure 3: Multiverse analysis compared to other approaches, from (Dragicevic et al. 2019).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: What is a multiverse analysis report? in (Hall et al. 2022).\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Multiverse analysis in Bayesian workflow in (Gelman et al. 2020).\n\n\n\n\n\n\nMultiverse analysis provides a way to transparently define and fit several models at once (Steegen et al. (2016)). This allows to define and investigate several models at once.\nIn a workflow that requires iterations, this could allow parallel exploration, thereby, increasing efficiency. On the other hand, this exploration of sets of models necessarily depends on researcher/data analyst/user choices, and is subject to computational and cognitive constraints.\nReasoning on a set of models can be challenging, and dependence structures and different weights of modelling choices are not immediately clear when confronted with a large collection of possible models (see e.g., Hall et al. (2022))."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#differences-and-structure-in-a-set-of-models",
    "href": "casestudies/workflows-multiverse/index.html#differences-and-structure-in-a-set-of-models",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Differences and structure in a set of models",
    "text": "Differences and structure in a set of models\nGiven a set of \\(m\\) models \\(\\mathcal{M} = \\{M_1, M_2, ..., M_m\\}\\), let \\(C_1, \\cdots, C_k\\) denote \\(k\\) different modelling choices. If, for example, \\(C_1 = \\{\\text{\"poisson\"}, \\text{\"negbinomial\"}\\}\\), \\(C_2 = \\{\\text{\"Trt\"}\\}\\) and \\(C_3 = \\{ \\text{\"no zAge\"}, \\text{\"zAge\"} \\}\\), one could draw networks of the resulting four models solely based on how much they differ in each of the conditions.\nBelow, the left-hand side shows one step differences, while the right-hand side includes two step differences for models created using the above modelling choices \\(C_1, C_2\\) and \\(C_3\\).\n\n\n\n\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nPoisson(Trt)\n\n\n\nB\n\nPoisson(Trt+zAge)\n\n\n\nA--B\n\n\n\n\nC\n\nNegbinom(Trt)\n\n\n\nA--C\n\n\n\n\nD\n\nNegbinom(Trt+zAge)\n\n\n\nB--D\n\n\n\n\nC--D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nPoisson(Trt)\n\n\n\nB\n\nPoisson(Trt+zAge)\n\n\n\nA--B\n\n\n\n\nC\n\nNegbinom(Trt)\n\n\n\nA--C\n\n\n\n\nD\n\nNegbinom(Trt+zAge)\n\n\n\nB--D\n\n\n\n\nC--B\n\n\n\n\n\n\nC--D\n\n\n\n\nD--A"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#filtering-and-flagging",
    "href": "casestudies/workflows-multiverse/index.html#filtering-and-flagging",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Filtering and Flagging",
    "text": "Filtering and Flagging\nWhat models need further investigation (or can be safely excluded) due to, for example\n\nprior-data conflict\nconvergence issues\ncalibration problems for posterior\nproblematic posterior predictive checks\ninsufficient predictive performance\n\nFiltering (or flagging) also serves as a tool to indicate that we are in fact at a certain decision point in the Bayesian workflow (e.g., if computation failed, go to “Addressing computational issues (5)”, see Figure 1).\nThen, we can fit models in parallel and evaluate the list of models jointly. This allows us to obtain joint summaries of model evaluation metrics for all models. An example of such a summary table is given below with results for the six models with highest PBMA weights and no divergent transitions in the collection of all \\(96\\) models.\n\n\n\n\n\n\n\nrhats_raw\ndiv_trans\nelpd_diff\nse_diff\nelpd_loo\nse_elpd_loo\np_loo\nse_p_loo\nlooic\nse_looic\npbma_weight\n\n\n\n\nnegbinomial(count ~ Trt+zBase+(1 | patient)), brms_default\n1.0019177\n0\n-0.6077353\n0.6633197\n-614.7457\n16.99723\n40.61555\n4.271803\n1229.491\n33.99447\n0.1030463\n\n\nnegbinomial(count ~ Trt+zBase+zAge+(1 | patient)), brms_default\n1.0009256\n0\n-0.9609591\n0.7357013\n-615.0990\n16.93908\n40.88040\n4.235912\n1230.198\n33.87816\n0.0732736\n\n\nnegbinomial(count ~ zBase * Trt+(1 | patient)), brms_default\n0.9999913\n0\n-1.0315128\n0.6751808\n-615.1695\n17.04660\n39.84465\n4.046008\n1230.339\n34.09320\n0.0674200\n\n\nnegbinomial(count ~ zBase * Trt+zAge+(1 | patient)), brms_default\n1.0012496\n0\n-1.4176538\n0.8658291\n-615.5557\n17.02404\n41.58619\n4.331625\n1231.111\n34.04808\n0.0465748\n\n\nnegbinomial(count ~ Trt+(1 | patient)), brms_default\n1.0041909\n0\n-4.5562196\n3.1165026\n-618.6942\n17.24316\n46.92558\n4.449165\n1237.388\n34.48633\n0.0158738\n\n\nnegbinomial(count ~ Trt+zAge+(1 | patient)), brms_default\n1.0010792\n0\n-4.6430282\n3.0686439\n-618.7810\n17.17285\n46.73492\n4.444467\n1237.562\n34.34569\n0.0139103"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Anna Elisabeth Riha",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n\n\n\nI am a doctoral researcher in the Probabilistic Machine Learning group at Aalto University supervised by Aki Vehtari and Antti Oulasvirta.\nMy research interests lie in Bayesian data analysis, modelling workflows, iteration in model building and metastatistics. I am interested in interdisciplinary perspectives on Bayesian workflows and building bridges between method development and applied research.\nOn this website, you will find information about my research projects as well as case studies and a blog with occasional random musings. Please feel free to contact me if you have any questions or would like to discuss potential projects.\nBefore my current position, I completed my MSc in Statistics at Humboldt University Berlin with a thesis project on hyperprior sensitivity of wrapped Gaussian processes including an application to wind data, supervised by Nadja Klein and Thomas Kneib. During my studies, I also worked as a research assistant in the group of Andreas Brandmaier in the project “Formal Methods in Lifespan Psychology” at Max Planck Institute for Human Development in Berlin. Before, I earned my BSc degree in Economics with a focus on Empirical Economics and a minor in Sociology from University Potsdam where I wrote my Bachelor thesis under the supervision of Marco Caliendo."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "arXiv Preprint (soon) | Code (soon)\nWhen building statistical models for Bayesian data analysis tasks, required and optional iterative adjustments and various modelling choices can give rise to numerous candidate models. Checks and evaluations throughout the modelling process can motivate changes to an existing model or the consideration of alternative models to ultimately obtain models of sufficient quality for the problem at hand. Additionally, failing to consider alternative models can lead to overconfidence in the predictive or inferential ability of a chosen model. Motivated by these challenges, this work proposes iterative filtering for multiverse analysis to support efficient and consistent assessment of multiple models and meaningful filtering towards fewer models of higher quality across different modelling contexts. Given that causal constraints have been taken into account, we show how multiverse analysis can be combined with recommendations from established Bayesian modelling workflows to identify promising candidate models by assessing predictive abilities and, if needed, tending to computational issues. We illustrate our suggested approach in common data analysis scenarios using real-world data."
  },
  {
    "objectID": "projects/index.html#supporting-bayesian-workflows-with-iterative-filtering-for-multiverse-analysis",
    "href": "projects/index.html#supporting-bayesian-workflows-with-iterative-filtering-for-multiverse-analysis",
    "title": "Projects",
    "section": "",
    "text": "arXiv Preprint (soon) | Code (soon)\nWhen building statistical models for Bayesian data analysis tasks, required and optional iterative adjustments and various modelling choices can give rise to numerous candidate models. Checks and evaluations throughout the modelling process can motivate changes to an existing model or the consideration of alternative models to ultimately obtain models of sufficient quality for the problem at hand. Additionally, failing to consider alternative models can lead to overconfidence in the predictive or inferential ability of a chosen model. Motivated by these challenges, this work proposes iterative filtering for multiverse analysis to support efficient and consistent assessment of multiple models and meaningful filtering towards fewer models of higher quality across different modelling contexts. Given that causal constraints have been taken into account, we show how multiverse analysis can be combined with recommendations from established Bayesian modelling workflows to identify promising candidate models by assessing predictive abilities and, if needed, tending to computational issues. We illustrate our suggested approach in common data analysis scenarios using real-world data."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "casestudies.html",
    "href": "casestudies.html",
    "title": "Case studies",
    "section": "",
    "text": "Iterative filtering for multiverse analyses of treatment effects\n\n\n\nmultiverse analysis\n\n\nBayesian workflows\n\n\n\n\n\n\n\nAnna Elisabeth Riha\n\n\nMay 23, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]