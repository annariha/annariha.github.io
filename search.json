[
  {
    "objectID": "casestudies/workflows-multiverse/index.html",
    "href": "casestudies/workflows-multiverse/index.html",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(readr)\nlibrary(tictoc)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(tinytable)\nlibrary(reactable)\nlibrary(htmltools)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(future)\nlibrary(furrr)\nlibrary(cmdstanr)\nlibrary(ggplot2)\nlibrary(ggdist)\nCan we combine transparent creation of sets of models (multiverse analysis) with recipes for model building and evaluation (Bayesian workflows) to support Bayesian modelling?\nBayesian modelling workflows consist of several intertwined tasks and can involve the iterative consideration of various candidate models (see, e.g., Gelman et al. (2020), Martin, Kumar, and Lao (2021)). Aspects like computation checks, model evaluation, model criticism and model comparison can motivate the consideration of multiple models and are essential when searching for models that are sufficient for obtaining accurate predictions and enabling robust decision-making (see, e.g., O’Hagan and Forster (2004), Vehtari and Ojanen (2012), Piironen and Vehtari (2017), Bürkner, Scholz, and Radev (2023)).\nMultiverse analysis provides a framework to transparently investigate several models at once (Steegen et al. (2016)). But reasoning on a set of models can be challenging, and dependence structures and different weights of modelling choices are not immediately clear when confronted with a large collection of possible models (see e.g., Hall et al. (2022)).\nIn this preprint, we propose iterative filtering for multiverse analysis to balance the advantages of a joint investigation of multiple candidate models with the potentially overwhelming tasks of evaluating and comparing multiple models at once."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#analysing-an-anticonvulsant-for-patients-with-epilepsy",
    "href": "casestudies/workflows-multiverse/index.html#analysing-an-anticonvulsant-for-patients-with-epilepsy",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Analysing an anticonvulsant for patients with epilepsy",
    "text": "Analysing an anticonvulsant for patients with epilepsy\nLet’s see how iterative filtering can be applied to multiverse analyses of anticonvulsant therapy for patients with epilepsy.\nWe use the dataset brms::epilepsy from the brms package (Bürkner 2017) with 236 observations of 59 patients. It was initially published by Leppik et al. (1987), and previously analysed, for example, by Thall and Vail (1990) and Breslow and Clayton (1993).\nThe data contains information on:\n\n\\(\\texttt{Trt}\\): 0 or 1 if patient received anticonvulsant therapy\n\\(\\texttt{Age}\\): age of patients in years\n\\(\\texttt{Base}\\): seizure count at 8-week baseline\n\\(\\texttt{zAge}\\): standardised age\n\\(\\texttt{zBase}\\): standardised baseline\n\\(\\texttt{patient}\\): patient number\n\\(\\texttt{visit}\\): session number from 1 (first visit) to 4 (last visit)\n\\(\\texttt{obs}\\): unique identifier for each observation\n\\(\\texttt{count}\\): seizure count between two visits.\n\nHere is a quick glimpse:\n\n\nCode\ntt(head(brms::epilepsy, 3))\n\n\n \n\n  \n    \n    \n    tinytable_1ab9mkmmlweun7kis5z4\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Age\n                Base\n                Trt\n                patient\n                visit\n                count\n                obs\n                zAge\n                zBase\n              \n        \n        \n        \n                \n                  31\n                  11\n                  0\n                  1\n                  1\n                  5\n                  1\n                   0.4249950\n                  -0.7571728\n                \n                \n                  30\n                  11\n                  0\n                  2\n                  1\n                  3\n                  2\n                   0.2652835\n                  -0.7571728\n                \n                \n                  25\n                   6\n                  0\n                  3\n                  1\n                  2\n                  3\n                  -0.5332740\n                  -0.9444033"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#an-initial-multiverse-of-models",
    "href": "casestudies/workflows-multiverse/index.html#an-initial-multiverse-of-models",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "An initial multiverse of models",
    "text": "An initial multiverse of models\nTo analyse the effect of anticonvulsant therapy on seizure counts, we choose models with Poisson and negative Binomial distributional families for the observations because they are suitable for non-negative integers. Additionally, we want to investigate default prior settings in brms as well as models with a horseshoe prior with three degrees of freedom for the population-level effects. Additionally, we evaluate different combinations of covariates as well as models with and without interaction effect zBase*Trt. The combination of these modelling choices leads to \\(2 \\times 2 \\times 6 = 24\\) candidate models.\n\n\nCode\n# create dataframe of combinations of model components ####\ncombinations_df &lt;- expand.grid(\n  family = names(list(poisson = poisson(), negbinomial = negbinomial())),\n  prior = list(brms_default = \"NULL\", brms_horseshoe = \"horseshoe(3)\"),\n  # population-level effects\n  Trt = c(\"\", \"Trt\"), \n  zBase = c(\"\", \"zBase\"),\n  zAge = c(\"\", \"zAge\")\n)\n\ncombinations_df &lt;- combinations_df |&gt; \n  # add interaction effect\n  mutate(zBaseTrt = factor(\n    case_when(\n      Trt == \"Trt\" ~ \"\",\n      Trt == \"\" ~ \"zBase * Trt\"))) |&gt; \n  # filter out rows with interaction and zBase\n  filter(!(zBaseTrt == \"zBase * Trt\" & combinations_df$zBase == \"zBase\"))\n\noutcome_str &lt;- \"count\" \n\ncombinations_df &lt;- combinations_df |&gt;  \n  # add outcome name \n  mutate(outcome = rep_len(outcome_str, NROW(combinations_df))) |&gt;\n  # add prior names for easier summarising, plotting etc. \n  mutate(priors = names(combinations_df$prior)) |&gt;\n  # reorder to have outcome name, family and treatment effects first \n  select(outcome, family, priors, prior, Trt, zBaseTrt, everything())\n\n\nFor the sake of simplicity, we do not fit all the models here but only show the code to obtain the modelfits and load a dataframe containing the modelfits for all 24 models.\n\n\nCode\n# load results for an initial multiverse of 24 models \ninitial_multiverse &lt;- readr::read_rds(here::here(\"data\", \"initial_multiverse.rds\"))\n\n\nBelow is the code that generates this dataframe. We set #| eval: false in the chunk options since we are not evaluating the code chunk here.\n\n\nCode\ninitial_multiverse &lt;- combinations_df |&gt;\n  mutate(modelnames = apply(combinations_df, 1, build_name))\n\n# workhorse: fit models ####\ntic()\nfuture::plan(multisession, workers = parallel::detectCores()-1)\ninitial_multiverse$modelfits &lt;- combinations_df |&gt;\n  group_nest(row_number()) |&gt;\n  pull(data) |&gt;\n  furrr::future_map(~build_fit(.x, dataset = brms::epilepsy), .options=furrr_options(seed=TRUE))\nfuture::plan(sequential)\ntoc()\n\n# add draws df ####\ninitial_multiverse &lt;- initial_multiverse |&gt;\n  mutate(model_id = paste0(\"Model \", row_number())) |&gt;\n  mutate(draws_df = purrr::map(purrr::map(modelfits, pluck), posterior::as_draws_df))\n\n\nTo fit the models, we use the below helper functions build_name(), build_brms_formula() and build_fit() for each row vector of modelling choices recorded in the initial dataframe. We set #| eval: false in the chunk options since we are not evaluating the code chunk here.\n\n\nCode\nbuild_name &lt;- function(row, ...){\n  outcome = row[[\"outcome\"]]\n  # prior names\n  priornames = row[[\"priors\"]]\n  in_id &lt;- c(which(!(names(row) %in% c(\"outcome\", \"family\", \"prior\", \"priors\")) & row != \"\"))\n  # cells that are included in the formula\n  covars &lt;- row[in_id]\n  # extract levels for formula\n  covars &lt;- as.character(unlist(covars))\n  # paste formula\n  formula1 = paste(outcome, \"~\", paste(covars, collapse = \"+\")) \n  # build name\n  name = paste0(row[[\"family\"]], \"(\", formula1, \"), \", priornames)\n  out &lt;- name\n}\n\nbuild_brms_formula &lt;- function(row, ...){\n  outcome = row[[\"outcome\"]]\n  fam = as.character(unlist(row[\"family\"]))\n  in_id &lt;- c(which(!(names(row) %in% c(\"outcome\", \"family\", \"prior\", \"priors\", \"model_name\")) & row != \"\"))\n  # cells that are included in the formula\n  covars &lt;- row[in_id]\n  # extract levels for formula\n  covars &lt;- as.character(unlist(covars))\n  # paste formula\n  formula_str = paste(outcome, \"~\", paste(covars, collapse = \"+\")) \n  # turn string into formula \n  formula = brms::brmsformula(as.formula(formula_str), family=fam)\n  out &lt;- formula \n} \n\nbuild_fit &lt;- function(row, dataset, ...){\n  # set priors \n  if (row[[\"priors\"]] == \"brms_horseshoe\"){\n    prior = brms::set_prior(\"horseshoe(3)\")\n  } else if (row[[\"priors\"]] == \"brms_default\"){\n    prior = NULL\n  }\n  # fit model with brms\n  brm(\n    formula = build_brms_formula(row), \n    data = dataset, \n    prior = prior,\n    seed = 424242,\n    backend = \"cmdstanr\", \n    silent = 2, \n    refresh = 0\n  ) \n}"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#evaluating-the-multiverse",
    "href": "casestudies/workflows-multiverse/index.html#evaluating-the-multiverse",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Evaluating the multiverse",
    "text": "Evaluating the multiverse\nWe use the loo package (Vehtari et al. 2020) to obtain estimates of expected log predictive densities (elpd) with PSIS-LOO-CV using loo::loo() and compare the predictive abilities of the models using loo::loo_compare(). For the purpose of this illustration, we load the loo-objects for all models that have been previously obtained and just present the code that was used to get the results for all models below.\n\n\nCode\n#loos_default\n\n\nAgain, we set #| eval: false in the chunk options since we are not evaluating the code chunk here.\n\n\nCode\n# workhorse: default PSIS-LOO-CV for all models ####\ntic()\nfuture::plan(multisession, workers = parallel::detectCores()-1)\nloos_default &lt;- initial_multiverse |&gt;\n  group_nest(row_number()) |&gt;\n  pull(data) |&gt;\n  furrr::future_map(~build_loos(.x, dataset = brms::epilepsy), .options=furrr_options(seed=TRUE))\ntoc()\nfuture::plan(sequential)\n\n# set names for loo objects\nnames(loos_default) &lt;- initial_multiverse$modelnames\n\n\nThe above code uses the following helper function build_loos() as a wrapper around loo::loo() to obtain estimates for elpd with PSIS-LOO-CV for one row in initial_multiverse.\n\n\nCode\n# loo: elpd and model comparison ####\nbuild_loos &lt;- function(row, dataset, ...){\n  modelfit = row[[\"modelfits\"]][[1]]\n  loo_object = loo(modelfit)\n  return(loo_object)\n}"
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#filtering-by-predictive-abilities",
    "href": "casestudies/workflows-multiverse/index.html#filtering-by-predictive-abilities",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Filtering by predictive abilities",
    "text": "Filtering by predictive abilities\nAs a first step, we filter out models with largely inferior predictive abilities."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#what-comes-next",
    "href": "casestudies/workflows-multiverse/index.html#what-comes-next",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "What comes next?",
    "text": "What comes next?\nIn part II of this case study, we will extend the filtered set of models by including more complex models and filter again. We will also show how we can use integrated PSIS-LOO-CV to obtain reliable estimates for elpd."
  },
  {
    "objectID": "casestudies/workflows-multiverse/index.html#appendix",
    "href": "casestudies/workflows-multiverse/index.html#appendix",
    "title": "Iterative filtering for multiverse analyses of treatment effects",
    "section": "Appendix",
    "text": "Appendix\n\nExisting work\n\nposterior calibration checks with Säilynoja, Bürkner, and Vehtari (2022)\nmodel comparison with \\(\\texttt{R}\\)-package loo (Vehtari et al. 2020)\nmultiverse analysis (Steegen et al. 2016) and multiverse \\(\\texttt{R}\\)-package (Sarma et al. 2021)\nexplorable multiverse analyses (Dragicevic et al. 2019)\ncreating multiverse analysis scripts, exploring results with Boba (Liu et al. 2021)\nsurvey of visualisation of multiverse analyses (Hall et al. 2022)\nmodular STAN (Bernstein, Vákár, and Wing 2020)\nmodelling multiverse analysis for machine learning (Bell et al. 2022)\n\nThe following figures show two variants of flowcharts for Bayesian workflows with different levels of detail1. The most apparent similarities are (1) the possibility to iterate when needed, and (2) connecting the tasks of modelling and checking and tending to computational issues.\n1 Another flowchart for Bayesian workflow can be found in Michael Betancourt’s blogpost “Principled Bayesian Workflow”.\n\n\n\n\n\n\n\n\n\n\n(a) Bayesian Workflow in (Gelman et al. 2020)\n\n\n\n\n\n\n\n\n\n\n\n(b) Bayesian Workflow in (Martin, Kumar, and Lao 2021).\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nChallenges in Bayesian workflows\n\nmulti-attribute multi-objective scenarios\nnavigating necessary vs. “nice-to-have” steps\nstopping criteria and sufficient exploration\niterative model building, while transparent and robust\ncommunicating results of multiple models\n\n\n\nTransparent Exploration with multiverse analysis\n\n\n\n\n\n\n\n\n\n\n\n(a) Multiverse analysis compared to other approaches, from (Dragicevic et al. 2019).\n\n\n\n\n\n\n\n\n\n\n\n(b) Multiverse analysis in Bayesian workflow in (Gelman et al. 2020).\n\n\n\n\n\n\n\nFigure 2\n\n\n\nMultiverse analysis provides a way to transparently define and fit several models at once (Steegen et al. (2016)). In a workflow that requires iterations, this could allow parallel exploration, thereby, increasing efficiency. On the other hand, this exploration of sets of models necessarily depends on researcher/data analyst/user choices, and is subject to computational and cognitive constraints.\nReasoning on a set of models can be challenging, and dependence structures and different weights of modelling choices are not immediately clear when confronted with a large collection of possible models (see e.g., Hall et al. (2022)).\n\n\nDifferences and structure in a set of models\nGiven a set of \\(m\\) models \\(\\mathcal{M} = \\{M_1, M_2, ..., M_m\\}\\), let \\(C_1, \\cdots, C_k\\) denote \\(k\\) different modelling choices. If, for example, \\(C_1 = \\{\\text{\"poisson\"}, \\text{\"negbinomial\"}\\}\\), \\(C_2 = \\{\\text{\"Trt\"}\\}\\) and \\(C_3 = \\{ \\text{\"no zAge\"}, \\text{\"zAge\"} \\}\\), one could draw networks of the resulting four models solely based on how much they differ in each of the conditions.\nBelow, the left-hand side shows one step differences, while the right-hand side includes two step differences for models created using the above modelling choices \\(C_1, C_2\\) and \\(C_3\\).\n\n\n\n\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nPoisson(Trt)\n\n\n\nB\n\nPoisson(Trt+zAge)\n\n\n\nA--B\n\n\n\n\nC\n\nNegbinom(Trt)\n\n\n\nA--C\n\n\n\n\nD\n\nNegbinom(Trt+zAge)\n\n\n\nB--D\n\n\n\n\nC--D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nPoisson(Trt)\n\n\n\nB\n\nPoisson(Trt+zAge)\n\n\n\nA--B\n\n\n\n\nC\n\nNegbinom(Trt)\n\n\n\nA--C\n\n\n\n\nD\n\nNegbinom(Trt+zAge)\n\n\n\nB--D\n\n\n\n\nC--B\n\n\n\n\n\n\nC--D\n\n\n\n\nD--A"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Anna Elisabeth Riha",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n\n\n\nI am a doctoral researcher in the Probabilistic Machine Learning group at Aalto University supervised by Aki Vehtari and Antti Oulasvirta.\nMy research interests lie in Bayesian data analysis, modelling workflows, iteration in model building and metastatistics. I am interested in interdisciplinary perspectives on Bayesian workflows and building bridges between method development and applied research.\nOn this website, you will find information about my research projects as well as case studies and a blog with occasional random musings. Please feel free to contact me if you have any questions or would like to discuss potential projects.\nBefore my current position, I completed my MSc in Statistics at Humboldt University Berlin with a thesis project on hyperprior sensitivity of wrapped Gaussian processes including an application to wind data, supervised by Nadja Klein and Thomas Kneib. During my studies, I also worked as a research assistant in the group of Andreas Brandmaier in the project “Formal Methods in Lifespan Psychology” at Max Planck Institute for Human Development in Berlin. Before, I earned my BSc degree in Economics with a focus on Empirical Economics and a minor in Sociology from University Potsdam where I wrote my Bachelor thesis under the supervision of Marco Caliendo."
  },
  {
    "objectID": "blogposts/index.html",
    "href": "blogposts/index.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "arXiv Preprint | Code | Blogpost\nWhen building statistical models for Bayesian data analysis tasks, required and optional iterative adjustments and different modelling choices can give rise to numerous candidate models. Checks and evaluations throughout the modelling process can motivate changes to an existing model or the consideration of alternatives. Failing to consider alternative models can lead to overconfidence in the predictive or inferential ability of a chosen model. The search for suitable models requires modellers to work with multiple models without jeopardising the validity of their results. Multiverse analysis enables the transparent creation of several models based on different modelling choices, but the number of models can become overwhelming in practice, and we require tools to reduce sets of models towards fewer models of higher quality across different modelling contexts. Motivated by these challenges, this work proposes iterative filtering for multiverse analysis to support efficient and consistent assessment of multiple models. Given that causal constraints have been considered, we show how multiverse analysis can be combined with recommendations from established Bayesian modelling workflows to identify promising candidate models by assessing predictive abilities and, if needed, tending to computational issues. We illustrate our suggested approach in different realistic modelling scenarios using real data examples."
  },
  {
    "objectID": "projects/index.html#supporting-bayesian-workflows-with-iterative-filtering-for-multiverse-analysis",
    "href": "projects/index.html#supporting-bayesian-workflows-with-iterative-filtering-for-multiverse-analysis",
    "title": "Projects",
    "section": "",
    "text": "arXiv Preprint | Code | Blogpost\nWhen building statistical models for Bayesian data analysis tasks, required and optional iterative adjustments and different modelling choices can give rise to numerous candidate models. Checks and evaluations throughout the modelling process can motivate changes to an existing model or the consideration of alternatives. Failing to consider alternative models can lead to overconfidence in the predictive or inferential ability of a chosen model. The search for suitable models requires modellers to work with multiple models without jeopardising the validity of their results. Multiverse analysis enables the transparent creation of several models based on different modelling choices, but the number of models can become overwhelming in practice, and we require tools to reduce sets of models towards fewer models of higher quality across different modelling contexts. Motivated by these challenges, this work proposes iterative filtering for multiverse analysis to support efficient and consistent assessment of multiple models. Given that causal constraints have been considered, we show how multiverse analysis can be combined with recommendations from established Bayesian modelling workflows to identify promising candidate models by assessing predictive abilities and, if needed, tending to computational issues. We illustrate our suggested approach in different realistic modelling scenarios using real data examples."
  },
  {
    "objectID": "casestudies/index.html",
    "href": "casestudies/index.html",
    "title": "Case studies",
    "section": "",
    "text": "Iterative filtering for multiverse analyses of treatment effects\n\n\n\nmultiverse analysis\n\n\nBayesian workflows\n\n\nbrms\n\n\n\n\n\n\n\nAnna Elisabeth Riha\n\n\nApr 5, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]